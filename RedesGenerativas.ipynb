{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo GAN \n",
    "*Las GAN son un tipo de algoritmo de aprendizaje no supervisado.*\n",
    "*Consisten en dos redes neuronales que compiten entre sí en un “juego de suma cero\"*.\n",
    "# Las dos partes: Generador y Discriminador:\n",
    "-Generador: Intenta crear datos que parezcan reales (por ejemplo, imágenes, música o texto).\n",
    "\n",
    "-Discriminador: Aprende a diferenciar entre datos reales y los generados por el generador.\n",
    "# El proceso:\n",
    "-El generador crea datos sintéticos.\n",
    "\n",
    "-El discriminador evalúa si estos datos son auténticos o falsos.\n",
    "# Ambas redes se mejoran mutuamente: \n",
    "el generador trata de engañar al discriminador, y este último se vuelve más hábil en detectar lo falso.\n",
    "# Aplicaciones:\n",
    "1. Generación de imágenes realistas.\n",
    "Completar datos faltantes en conjuntos de datos.\n",
    "2. Creación de música original.\n",
    "3. Traducción automática de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import , division , print_function , unicode_literals\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tran_images , train_labels) , (_,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*visualizacion de la cantidad de imagenes del set de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*mostrando las labels o etiquetas del set de datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformando imagenes:\n",
    "- Paso necesario para trabajar con ellas de manera adecuada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formato (28,28) y se le agrega una dimension mas\n",
    "# tran_images.shape[0] -> referencia que se trabajan con las 60mil imagenes\n",
    "train_images= tran_images.reshape(tran_images.shape[0],28,28,1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizacion de las Imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eligiendo la cantidad de imagenes que se van a utilizar\n",
    "*(en este caso particular todas las del set)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantida de imagenes\n",
    "BUFFER_SIZE = 60000\n",
    "#Cantidad de lotes de imagenes\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizacion del Set de Datos\n",
    "- Como se esta trabajando con una sola dimension de color la imagen va a ser de color gris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1898c369240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[110].reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Generador \n",
    "- Toma una señal de ruido aleatorio y emite imagenes\n",
    "- El generador trata de generar imagenes falsas que son similares a las reales\n",
    "- El objetivo del generador es engañar al discriminador\n",
    "- Las etiquetas estan marcadas de la siguiente manera:\n",
    "1. la etiqueta = 1.0 -> indica imagenes reales\n",
    "2. la etiqueta = 0.0 -> indica que son imagenes falsas\n",
    "- El generador utiliza tf.keras.layers.Conv2DTranspose (upsampling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion Generador \n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    # 1er capa \n",
    "    model.add(layers.Dense(7*7*256, use_bias=False , input_shape=(100,)))\n",
    "    # capa de normalizacion\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # capa relu para activacion\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # capa de reformacion de la imagen\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    # Debido que se utiliza el \"mismo\" relleno y los saltos (strides) = 1:\n",
    "    # capas de convolucion: con 128 filtros de 5 x 5\n",
    "    model.add(layers.Conv2DTranspose(128,(5,5) , \n",
    "                                     strides=(1,1),\n",
    "                                     padding=\"same\",\n",
    "                                     use_bias=False \n",
    "                                     ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # capas de convolucion: con 64 filtros de 5 x 5, con saltos de 2 en 2 \n",
    "    model.add(layers.Conv2DTranspose(64,(5,5) , \n",
    "                                     strides=(2,2),\n",
    "                                     padding=\"same\",\n",
    "                                     use_bias=False \n",
    "                                     ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # capas de convolucion: con 1 filtro de 5 x 5, con saltos de 2 en 2\n",
    "    # neurona de salida \n",
    "    model.add(layers.Conv2DTranspose(1,(5,5) , \n",
    "                                     strides=(2,2),\n",
    "                                     padding=\"same\",\n",
    "                                     use_bias=False,\n",
    "                                     activation=\"tanh\" \n",
    "                                     ))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CURSOS\\NOTEBOOKS\\Redes Generativas Adversariales\\RedesGenerativasAdversariales\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,254,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,176</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │     \u001b[38;5;34m1,254,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │        \u001b[38;5;34m50,176\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m819,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m204,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m1,600\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,330,944</span> (8.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,330,944\u001b[0m (8.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,305,472</span> (8.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,305,472\u001b[0m (8.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,472</span> (99.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25,472\u001b[0m (99.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Ruido Aleatorio en las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = tf.random.normal([1,100])\n",
    "generated_image=generator(noise, training=False)\n",
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1898c47f4f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagen_falsa= plt.imshow(generated_image[0,:,:,0] , cmap=\"gray\")\n",
    "imagen_falsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando el Discriminador de las Imagenes\n",
    "- Esta entrenado para hacer lo siguiente:\n",
    "1. salida 0 (probabilidad = 0%) cuando la imagen de entrada es falsa\n",
    "2. salida 1 (probabilidad = 100%) cuando la imagen de entrada es real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    # Se crea un modelo secuencial vacío\n",
    "    # Las capas se agregarán secuencialmente\n",
    "    model = tf.keras.Sequential()\n",
    "    # La primera tiene 64 filtros, un tamaño de kernel de (5, 5), \n",
    "    # un stride de (2, 2) y utiliza la función de activación LeakyReLU.\n",
    "    model.add(layers.Conv2D(64, (5, 5), \n",
    "                            strides=(2, 2), \n",
    "                            padding='same', \n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # Se agrega una capa de dropout con una tasa del 30%,\n",
    "    # después de cada capa convolucional para evitar el sobreajuste.\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    #La segunda tiene 128 filtros, un tamaño de kernel de (5, 5), \n",
    "    # un stride de (2, 2) y también utiliza LeakyReLU.\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    # Capa dropout para evitar sobreajuste\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # Se agrega una capa Flatten para aplanar la salida de las capas convolucionales.\n",
    "    model.add(layers.Flatten())\n",
    "    # Se agrega una capa densa con una sola neurona \n",
    "    # (para la clasificación binaria) sin función de activación explícita.\n",
    "    model.add(layers.Dense(1))\n",
    "    # Se muestra un resumen del modelo.\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CURSOS\\NOTEBOOKS\\Redes Generativas Adversariales\\RedesGenerativasAdversariales\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m204,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m6,273\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m212,865\u001b[0m (831.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,865</span> (831.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,865\u001b[0m (831.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haciendo predicciones con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la imagenAxesImage(shape=(28, 28)) la decision es [[-0.0002385]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Para la imagen{imagen_falsa} la decision es {decision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de Perdida para el Generador\n",
    "- Calcula la perdida que es la diferencia entre las decisiones y la realidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropia cruzada\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La perdida del discriminador indica lo bien que el discriminador es capaz de distinguir imagenes reales de imagenes falsas\n",
    "- comprara las predicciones del discriminador sobre las imagenes reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output , fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output )\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion de perdida del Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta funcion de perdida del generador cuantifica lo bien que fue capaz de engañar al discriminador las imagenes hechas por el generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output) , fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generando Optimizador Adam \n",
    "- El optimizador Adam se utiliza comúnmente en GANs debido a su eficacia en la optimización de redes neuronales. \n",
    "- El valor 1e-4 representa la tasa de aprendizaje (learning rate) utilizada por el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando Checkpoints para la Red\n",
    "- Este fragmento de código configura la gestión de checkpoints para un modelo GAN (Generative Adversarial Network).\n",
    "- Los checkpoints son importantes para asegurar que puedas guardar el progreso del entrenamiento y recuperarlo en caso de interrupciones o para evaluar el modelo después del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directorio\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "#Creacion de la Ruta\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# Creacion del objeto de guardado\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del Modelo\n",
    "- configuracion de parámetros importantes para el entrenamiento y la generación de ejemplos en una red GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se establece el número total de épocas (iteraciones completas a través del conjunto de datos) \n",
    "#EPOCHS = 100\n",
    "EPOCHS = 30 # -> \n",
    "# La dimensión del ruido es la longitud del vector de entrada aleatorio que se utiliza como entrada para el generado\n",
    "noise_dim = 100\n",
    "# Definicion de los ejemplos generados\n",
    "num_examples_to_generate = 16\n",
    "# se crea una matriz de numeros aleatorios extraidos de una distribucion normal(Gaussiana)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta función representa un paso de entrenamiento en una red GAN. El generador intenta generar imágenes más realistas, mientras que el discriminador aprende a distinguir entre imágenes reales y generadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    #se crea un tensor de ruido aleatorio utilizando la distribución normal (Gaussiana)\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim]) # BATCH_SIZE -> tamaño lote , noise_dim es la dimensión del espacio de ruido.\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      #Se llama al generador con la entrada de ruido aleatorio (noise). \n",
    "      # Esto genera imágenes sintéticas (falsas) \n",
    "      # que se utilizarán para engañar al discriminador.\n",
    "      generated_images = generator(noise, training=True) \n",
    "      #El discriminador evalúa las imágenes reales (images)+\n",
    "      # y calcula la salida (probabilidad) de que sean reales\n",
    "      real_output = discriminator(images, training=True) \n",
    "      #: El discriminador también evalúa las imágenes generadas (generated_images) \n",
    "      # y calcula la salida (probabilidad) de que sean falsas.\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "      \n",
    "      # Se calcula la pérdida del generador utilizando la salida \n",
    "      # del discriminador para las imágenes generadas\n",
    "      gen_loss = generator_loss(fake_output) \n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    # Aplicando optimizacion al optimizador y discriminador \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) \n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    # Aplicando gradientes al optimizador tanto del generador como el discriminador\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) \n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Producir imágenes para el GIF sobre la marcha\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Guardar el modelo cada 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Tiempo de epoca {} es {} segundos'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generar luego del epoch final\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('imagen_de_epoca_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'EPOCHS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'EPOCHS'"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se restaura el modelo desde el último punto de control (checkpoint) \n",
    "# guardado en el directorio especificado (checkpoint_dir)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\CURSOS\\\\NOTEBOOKS\\\\Redes Generativas Adversariales\\\\imagen_de_epoca_ 100.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_image\u001b[39m(epoch_no):\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagen_de_epoca_\u001b[39m\u001b[38;5;132;01m{:4d}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_no))\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdisplay_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 11\u001b[0m, in \u001b[0;36mdisplay_image\u001b[1;34m(epoch_no)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay_image\u001b[39m(epoch_no):\n\u001b[1;32m---> 11\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagen_de_epoca_\u001b[39;49m\u001b[38;5;132;43;01m{:4d}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_no\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CURSOS\\NOTEBOOKS\\Redes Generativas Adversariales\\RedesGenerativasAdversariales\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\CURSOS\\\\NOTEBOOKS\\\\Redes Generativas Adversariales\\\\imagen_de_epoca_ 100.png'"
     ]
    }
   ],
   "source": [
    "# Mostrar una sola imagen usando el número de Epoch\n",
    "# La función abre y devuelve una imagen con nombre de archivo formateado según \n",
    "# el número de época proporcionado. Ejemplo, si epoch_no es 100,\n",
    "# buscará y mostrará la imagen llamada “image_at_epoch_0100.png”.\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('imagen_de_epoca_{:4d}.png'.format(epoch_no))\n",
    "\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'imagen_de_epoca_0100.png' no se encontró en la ubicación especificada.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\CURSOS\\\\NOTEBOOKS\\\\Redes Generativas Adversariales\\\\imagen_de_epoca_0100.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Supongamos que EPOCHS contiene el número de la última época registrado\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# (asegúrate de asignar el valor correcto antes de llamar a la función)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m last_epoch_number \u001b[38;5;241m=\u001b[39m EPOCHS\n\u001b[1;32m---> 14\u001b[0m last_epoch_image \u001b[38;5;241m=\u001b[39m \u001b[43mdisplay_last_epoch_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_epoch_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m last_epoch_image\u001b[38;5;241m.\u001b[39mshow()  \u001b[38;5;66;03m# Esto mostrará la imagen en tu visor de imágenes predeterminado\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_epoch_image:\n",
      "Cell \u001b[1;32mIn[63], line 10\u001b[0m, in \u001b[0;36mdisplay_last_epoch_image\u001b[1;34m(last_epoch)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEl archivo \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m no se encontró en la ubicación especificada.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CURSOS\\NOTEBOOKS\\Redes Generativas Adversariales\\RedesGenerativasAdversariales\\lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\CURSOS\\\\NOTEBOOKS\\\\Redes Generativas Adversariales\\\\imagen_de_epoca_0100.png'"
     ]
    }
   ],
   "source": [
    "# Mostrar la imagen correspondiente a la última época registrada\n",
    "def display_last_epoch_image(last_epoch):\n",
    "    filename = 'imagen_de_epoca_{:01d}.png'.format(last_epoch)\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        return PIL.Image.open(filename)\n",
    "    else:\n",
    "        print(f\"El archivo '{filename}' no se encontró en la ubicación especificada.\")\n",
    "        \n",
    "    return PIL.Image.open(filename)\n",
    "# Supongamos que EPOCHS contiene el número de la última época registrado\n",
    "# (asegúrate de asignar el valor correcto antes de llamar a la función)\n",
    "last_epoch_number = EPOCHS\n",
    "last_epoch_image = display_last_epoch_image(last_epoch_number)\n",
    "last_epoch_image.show()  # Esto mostrará la imagen en tu visor de imágenes predeterminado\n",
    "if last_epoch_image:\n",
    "    last_epoch_image.show()  # Esto mostrará la imagen en tu visor de imágenes predeterminado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedesGenerativasAdversariales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
